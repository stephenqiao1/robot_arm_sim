import os
import math
import random
import shutil

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sn

import tensorflow as tf
from tensorflow import keras
from keras import layers

BASE_DIR = "star-wars-images/"
names = ["YODA", "LUKE SKYWALKER", "R2-R2", "MACE WINDU", "GENERAL GRIEVOUS"]

tf.random.set_seed(1)

# Read information about dataset
if not os.path.isdir(BASE_DIR + "train/"):
    for name in names:
        os.makedirs(BASE_DIR + "train/" + name)
        os.makedirs(BASE_DIR + "val/" + name)
        os.makedirs(BASE_DIR + "test/" + name)

# Total number of classes in the dataset
# orig_folders = ["0001/", "0002/", "0003/", "0004/", "0005/"]
# for folder_idx, folder in enumerate(orig_folders):
#     files = os.listdir(BASE_DIR + folder)
#     number_of_images = len([name for name in files])
#     n_train = int((number_of_images * 0.6) + 0.5)
#     n_valid = int((number_of_images * 0.25) + 0.5)
#     n_test = number_of_images - n_train - n_valid
#     print(number_of_images, n_train, n_valid, n_test)
#     for idx, file in enumerate(files):
#         file_name = BASE_DIR + folder + file
#         if idx < n_train:
#             shutil.move(file_name, BASE_DIR + "train/" + names[folder_idx])
#         elif idx < n_train + n_valid:
#             shutil.move(file_name, BASE_DIR + "val/" + names[folder_idx])
#         else:
#             shutil.move(file_name, BASE_DIR + "test/" + names[folder_idx])

# Generate batches of tensor image data with real-time data augmentation

# preprocessing function
# rescale=1./255 -> [0, 1]
train_gen = keras.preprocessing.image.ImageDataGenerator(
    rescale=1.0 / 255,
    # rotation_range=20,
    # horizontal_flip=True,
    # width_shift_range=0.2,
    # height_shift_range=0.2,
    # shear_range=0.2,
    # zoom_range=0.2,
)
valid_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)
test_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)

train_batches = train_gen.flow_from_directory(
    "star-wars-images/train",
    target_size=(256, 256),
    class_mode="sparse",
    batch_size=4,
    shuffle=True,
    color_mode="rgb",
    classes=names,
)

val_batches = valid_gen.flow_from_directory(
    "star-wars-images/val",
    target_size=(256, 256),
    class_mode="sparse",
    batch_size=4,
    shuffle=False,
    color_mode="rgb",
    classes=names,
)

test_batches = test_gen.flow_from_directory(
    "star-wars-images/test",
    target_size=(256, 256),
    class_mode="sparse",
    batch_size=4,
    shuffle=False,
    color_mode="rgb",
    classes=names,
)

train_batch = train_batches[0]
print(train_batch[0].shape)
print(train_batch[1])
test_batch = test_batches[0]
print(test_batch[0].shape)
print(test_batch[1])


def show(batch, pred_labels=None):
    plt.figure(figsize=(10, 10))
    for i in range(4):
        plt.subplot(2, 2, i + 1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(batch[0][i], cmap=plt.cm.binary)
        # The CIFAR labels happen to be arrays,
        # which is why you need the extra index
        lbl = names[int(batch[1][i])]
        if pred_labels is not None:
            lbl += "/ Pred:" + names[int(pred_labels[i])]
        plt.xlabel(lbl)
    plt.show()

# show(test_batch)
# show(train_batch)

model = keras.models.Sequential()
model.add(layers.Conv2D(32, (3,3), strides=(1,1), padding="valid", activation='relu', input_shape=(256, 256, 3)))
model.add(layers.MaxPool2D((2,2)))
model.add(layers.Conv2D(64, 3, activation='relu'))
model.add(layers.MaxPool2D((2,2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(5))
print(model.summary())

# loss and optimizer
loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optim = keras.optimizers.Adam(learning_rate=0.001)
metrics = ["accuracy"]

model.compile(optimizer=optim, loss=loss, metrics=metrics)

# training
epochs = 30

# callbacks
early_stopping = keras.callbacks.EarlyStopping(
    monitor="val_loss",
    patience=5,
    verbose=2
)

history = model.fit(train_batches, validation_data=val_batches, callbacks=[early_stopping], epochs=epochs, verbose=2)

model.save("lego_model.keras")

# plot loss and accuracy
plt.figure(figsize=(16,6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='valid loss')
plt.grid()
plt.legend(fontsize=15)

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='valid acc')
plt.grid()
plt.legend(fontsize=15)

model.evaluate(test_batches, verbose=2)

predictions = model.predict(test_batches)
predictions = tf.nn.softmax(predictions)
labels = np.argmax(predictions, axis=1)

print(test_batches[0][1])
print(labels[0:4])

show(test_batches[0], labels[0:4])